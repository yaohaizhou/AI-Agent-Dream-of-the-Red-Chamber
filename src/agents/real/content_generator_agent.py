#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å†…å®¹ç”ŸæˆAgent
è´Ÿè´£ç”Ÿæˆé«˜è´¨é‡çš„å¤å…¸æ–‡å­¦ç»­å†™å†…å®¹
"""

import asyncio
from typing import Dict, List, Any, Optional
from datetime import datetime
import re

from ..base import BaseAgent, AgentResult
from ..gpt5_client import get_gpt5_client
from ...config.settings import Settings
from ...prompts.literary_prompts import get_literary_prompts


class ContentGeneratorAgent(BaseAgent):
    """å†…å®¹ç”ŸæˆAgent"""

    def __init__(self, settings: Settings):
        super().__init__("å†…å®¹ç”ŸæˆAgent", {"task": "å¤å…¸æ–‡å­¦å†…å®¹åˆ›ä½œ"})
        self.settings = settings
        self.gpt5_client = get_gpt5_client(settings)
        self.prompts = get_literary_prompts()

        # å¤å…¸æ–‡å­¦é£æ ¼ç‰¹å¾
        self.literary_features = self._load_literary_features()

    def _load_literary_features(self) -> Dict[str, Any]:
        """åŠ è½½å¤å…¸æ–‡å­¦é£æ ¼ç‰¹å¾"""
        return {
            "language_patterns": [
                "é›…è‡´å¤æœ´", "æ–‡è¾ä¼˜ç¾", "éŸµå‘³æ‚ é•¿",
                "ç¬¬ä¸‰äººç§°å…¨çŸ¥è§†è§’", "è¯¦ç•¥å¾—å½“"
            ],
            "rhetorical_devices": [
                "æ¯”å–»", "æ‹Ÿäºº", "å¯¹ä»—", "æ’æ¯”",
                "åé—®", "è®¾é—®", "è±¡å¾", "æš—ç¤º"
            ],
            "structural_elements": [
                "å¼€ç«¯", "å‘å±•", "é«˜æ½®", "ç»“å±€",
                "ä¼ç¬”", "ç…§åº”", "ç‚¹é¢˜", "å‡å"
            ],
            "classical_motifs": [
                "è¯—è¯å”±å’Œ", "æ¢¦å¢ƒæå†™", "æ™¯ç‰©çƒ˜æ‰˜",
                "å¿ƒç†åˆ»ç”»", "ç»†èŠ‚æå†™", "è±¡å¾æ‰‹æ³•"
            ]
        }

    async def process(self, input_data: Dict[str, Any]) -> AgentResult:
        """ç”Ÿæˆç»­å†™å†…å®¹"""
        self.update_status("generating")

        try:
            print("ğŸ¨ [DEBUG] ContentGeneratorAgent å¼€å§‹å¤„ç†")
            print(f"ğŸ¨ [DEBUG] è¾“å…¥æ•°æ®: {input_data}")

            # æ£€æŸ¥æ˜¯å¦æœ‰åé¦ˆæ¶ˆæ¯éœ€è¦å¤„ç†
            feedback_messages = await self.get_feedback_messages()
            improvement_context = self._process_feedback_messages(feedback_messages)
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ”¹è¿›è¯·æ±‚
            is_improvement = input_data.get("improvement_suggestions") or input_data.get("quality_feedback")
            if is_improvement:
                print("ğŸ”„ [DEBUG] æ£€æµ‹åˆ°æ”¹è¿›è¯·æ±‚ï¼Œå°†åŸºäºåé¦ˆä¼˜åŒ–å†…å®¹")
                return await self._generate_improved_content(input_data, improvement_context)

            strategy_data = input_data.get("strategy", {})
            chapters_to_generate = input_data.get("chapters", 81)

            print(f"ğŸ¨ [DEBUG] ç­–ç•¥æ•°æ®: {strategy_data}")
            print(f"ğŸ¨ [DEBUG] éœ€è¦ç”Ÿæˆç« èŠ‚æ•°: {chapters_to_generate}")

            plot_outline = strategy_data.get("plot_outline", [])
            print(f"ğŸ¨ [DEBUG] æƒ…èŠ‚å¤§çº²åŒ…å« {len(plot_outline)} ä¸ªç« èŠ‚")

            # ç”Ÿæˆæ‰€æœ‰ç« èŠ‚å†…å®¹
            generated_chapters = []

            for i, chapter_info in enumerate(plot_outline[:chapters_to_generate]):
                print(f"ğŸ¨ [DEBUG] å¼€å§‹ç”Ÿæˆç¬¬ {i+1} ç« : {chapter_info}")

                # ç”Ÿæˆå•ä¸ªç« èŠ‚
                chapter_content = await self._generate_chapter_content(
                    chapter_info,
                    strategy_data,
                    input_data.get("knowledge_base", {})
                )

                print(f"ğŸ¨ [DEBUG] ç¬¬ {i+1} ç« ç”Ÿæˆç»“æœ: success={chapter_content['success']}")

                if chapter_content["success"]:
                    generated_chapters.append(chapter_content["content"])
                    print(f"ğŸ¨ [DEBUG] ç¬¬ {i+1} ç« ç”ŸæˆæˆåŠŸï¼Œé•¿åº¦: {len(chapter_content['content'])}")
                else:
                    # ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹
                    fallback_content = self._generate_fallback_content(chapter_info)
                    generated_chapters.append(fallback_content)
                    print(f"ğŸ¨ [DEBUG] ç¬¬ {i+1} ç« ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨å¤‡ç”¨å†…å®¹")

            print(f"ğŸ¨ [DEBUG] æ€»å…±ç”Ÿæˆ {len(generated_chapters)} ä¸ªç« èŠ‚")

            result_data = {
                "chapters": generated_chapters,
                "total_chapters": len(generated_chapters),
                "generation_stats": {
                    "success_rate": len([c for c in generated_chapters if "error" not in c]) / len(generated_chapters) if generated_chapters else 0,
                    "average_length": sum(len(c) for c in generated_chapters) / len(generated_chapters) if generated_chapters else 0,
                    "timestamp": datetime.now().isoformat()
                }
            }

            print(f"ğŸ¨ [DEBUG] ç”Ÿæˆç»Ÿè®¡: {result_data['generation_stats']}")

            self.update_status("completed")

            return AgentResult(
                success=True,
                data=result_data,
                message=f"æˆåŠŸç”Ÿæˆ{len(generated_chapters)}å›ç»­å†™å†…å®¹"
            )

        except Exception as e:
            print(f"ğŸ¨ [DEBUG] ContentGeneratorAgent å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"ğŸ¨ [DEBUG] å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}")
            self.update_status("error")
            return self.handle_error(e)

    async def _generate_chapter_content(
        self,
        chapter_info: Dict[str, Any],
        strategy_data: Dict[str, Any],
        knowledge_base: Dict[str, Any]
    ) -> Dict[str, Any]:
        """ç”Ÿæˆå•ä¸ªç« èŠ‚å†…å®¹"""
        try:
            print(f"ğŸ“ [DEBUG] å¼€å§‹ç”Ÿæˆç« èŠ‚ {chapter_info.get('chapter_num', 'unknown')}")

            chapter_num = chapter_info["chapter_num"]
            chapter_title = chapter_info["title"]
            key_events = chapter_info["key_events"]
            character_development = chapter_info["character_development"]

            print(f"ğŸ“ [DEBUG] ç« èŠ‚ä¿¡æ¯: {chapter_num}, {chapter_title}")
            print(f"ğŸ“ [DEBUG] å…³é”®äº‹ä»¶: {key_events}")
            print(f"ğŸ“ [DEBUG] äººç‰©å‘å±•: {character_development}")

            # æ„å»ºç”Ÿæˆprompt
            print("ğŸ“ [DEBUG] æ„å»ºç”Ÿæˆä¸Šä¸‹æ–‡...")
            context = self._build_generation_context(
                chapter_info, strategy_data, knowledge_base
            )
            print(f"ğŸ“ [DEBUG] ä¸Šä¸‹æ–‡é•¿åº¦: {len(context)}")

            print("ğŸ“ [DEBUG] åˆ›å»ºpromptæ¨¡æ¿...")
            system_msg, user_prompt = self.prompts.create_custom_prompt(
                "content_generator",
                {
                    "chapter_num": chapter_num,
                    "chapter_title": chapter_title,
                    "chapter_summary": "; ".join(key_events),
                    "key_characters": ", ".join(character_development.keys()),
                    "theme_focus": ", ".join(chapter_info.get("themes", []))
                }
            )

            print(f"ğŸ“ [DEBUG] System messageé•¿åº¦: {len(system_msg)}")
            print(f"ğŸ“ [DEBUG] User prompté•¿åº¦: {len(user_prompt)}")

            # æ·»åŠ ä¸Šä¸‹æ–‡ä¿¡æ¯
            full_prompt = user_prompt + "\n\nå‚è€ƒä¸Šä¸‹æ–‡ï¼š\n" + context
            print(f"ğŸ“ [DEBUG] å®Œæ•´prompté•¿åº¦: {len(full_prompt)}")

            # è°ƒç”¨GPT-5ç”Ÿæˆå†…å®¹
            print("ğŸ“ [DEBUG] è°ƒç”¨GPT-5 API...")
            response = await self.gpt5_client.generate_with_retry(
                prompt=full_prompt,
                system_message=system_msg,
                temperature=0.8,
                max_tokens=8000
            )

            print(f"ğŸ“ [DEBUG] APIå“åº”: success={response.get('success', False)}")

            if response["success"]:
                print("ğŸ“ [DEBUG] APIè°ƒç”¨æˆåŠŸï¼Œå¼€å§‹åå¤„ç†...")
                content = self._post_process_content(response["content"], chapter_info)
                print(f"ğŸ“ [DEBUG] åå¤„ç†å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(content)}")
                return {
                    "success": True,
                    "content": content,
                    "chapter_num": chapter_num,
                    "word_count": len(content),
                    "generation_info": response
                }
            else:
                print(f"ğŸ“ [DEBUG] APIè°ƒç”¨å¤±è´¥: {response.get('error', 'unknown error')}")
                return {
                    "success": False,
                    "error": response.get("error", "ç”Ÿæˆå¤±è´¥"),
                    "chapter_num": chapter_num
                }

        except Exception as e:
            print(f"ğŸ“ [DEBUG] ç”Ÿæˆç« èŠ‚å¼‚å¸¸: {str(e)}")
            import traceback
            print(f"ğŸ“ [DEBUG] å¼‚å¸¸è¯¦æƒ…:\n{traceback.format_exc()}")
            return {
                "success": False,
                "error": str(e),
                "chapter_num": chapter_info.get("chapter_num")
            }

    def _build_generation_context(
        self,
        chapter_info: Dict[str, Any],
        strategy_data: Dict[str, Any],
        knowledge_base: Dict[str, Any]
    ) -> str:
        """æ„å»ºç”Ÿæˆä¸Šä¸‹æ–‡"""
        context_parts = []

        # æ·»åŠ æƒ…èŠ‚å¤§çº²
        plot_outline = strategy_data.get("overall_strategy", {})
        if plot_outline:
            context_parts.append(f"æ€»ä½“æƒ…èŠ‚æ¡†æ¶: {plot_outline.get('overall_approach', '')}")

        # æ·»åŠ äººç‰©ä¿¡æ¯
        characters = knowledge_base.get("characters", {})
        if characters:
            char_info = []
            for name, info in list(characters.items())[:3]:  # é™åˆ¶å‰3ä¸ªä¸»è¦äººç‰©
                char_info.append(f"{name}: {info.get('æ€§æ ¼', '')}")
            context_parts.append(f"ä¸»è¦äººç‰©æ€§æ ¼: {'; '.join(char_info)}")

        # æ·»åŠ ä¸»é¢˜ä¿¡æ¯
        themes = chapter_info.get("themes", [])
        if themes:
            context_parts.append(f"æœ¬å›ä¸»é¢˜: {'ã€'.join(themes)}")

        # æ·»åŠ æ–‡å­¦è¦æ±‚
        literary_reqs = [
            "ä½¿ç”¨é›…è‡´å¤æœ´çš„å¤å…¸å°è¯´è¯­è¨€",
            "èå…¥è¯—è¯æ­Œèµ‹ç­‰å¤å…¸å…ƒç´ ",
            "æ³¨é‡äººç‰©å¿ƒç†æå†™",
            "è¿ç”¨åˆé€‚çš„ä¿®è¾æ‰‹æ³•"
        ]
        context_parts.append(f"æ–‡å­¦è¦æ±‚: {'ï¼›'.join(literary_reqs)}")

        return "\n".join(context_parts)

    def _post_process_content(self, raw_content: str, chapter_info: Dict[str, Any]) -> str:
        """åå¤„ç†ç”Ÿæˆçš„å†…å®¹"""
        try:
            # æ¸…ç†å’Œæ ¼å¼åŒ–å†…å®¹
            content = self._clean_content(raw_content)

            # æ·»åŠ ç« èŠ‚æ ‡é¢˜
            chapter_title = chapter_info.get("title", f"ç¬¬{chapter_info['chapter_num']}å›")
            formatted_content = f"### {chapter_title}\n\n{content}"

            # æ·»åŠ ç« èŠ‚ä¿¡æ¯
            chapter_info_text = self._generate_chapter_info(chapter_info)
            formatted_content = chapter_info_text + "\n\n" + formatted_content

            # æ·»åŠ ç»“å°¾æ ‡è®°
            formatted_content += "\n\n---\n\n*æœ¬å›ç”±AIç»­å†™ï¼Œä¿æŒå¤å…¸æ–‡å­¦é£æ ¼*"

            return formatted_content

        except Exception as e:
            print(f"å†…å®¹åå¤„ç†å¤±è´¥: {e}")
            return raw_content

    def _clean_content(self, content: str) -> str:
        """æ¸…ç†å†…å®¹æ ¼å¼"""
        # ç§»é™¤å¤šä½™çš„æ¢è¡Œ
        content = re.sub(r'\n{3,}', '\n\n', content)

        # ç»Ÿä¸€æ®µè½æ ¼å¼
        content = re.sub(r'^', '    ', content, flags=re.MULTILINE)

        # æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        content = content.replace('\r', '')

        return content.strip()

    def _generate_chapter_info(self, chapter_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆç« èŠ‚ä¿¡æ¯"""
        info_lines = []

        chapter_num = chapter_info.get("chapter_num")
        phase = chapter_info.get("phase", "")
        focus = chapter_info.get("focus", "")

        info_lines.append(f"**ç¬¬{chapter_num}å›**")
        if phase:
            info_lines.append(f"**é˜¶æ®µ**: {phase}")
        if focus:
            info_lines.append(f"**é‡ç‚¹**: {focus}")

        return "\n".join(info_lines)

    def _generate_fallback_content(self, chapter_info: Dict[str, Any]) -> str:
        """ç”Ÿæˆå¤‡ç”¨å†…å®¹"""
        chapter_num = chapter_info["chapter_num"]
        chapter_title = chapter_info.get("title", f"ç¬¬{chapter_num}å› (å¤‡ç”¨å†…å®¹)")

        content = f"""### {chapter_title}

[è¿™æ˜¯ç¬¬{chapter_num}å›çš„å¤‡ç”¨å†…å®¹]

è¯è¯´...

[æ­¤å¤„çœç•¥è¯¦ç»†å†…å®¹]

---

*æœ¬å›å¤‡ç”¨å†…å®¹ï¼Œç­‰å¾…è¿›ä¸€æ­¥å®Œå–„*
"""

        return content

    def _ensure_literary_quality(self, content: str) -> str:
        """ç¡®ä¿æ–‡å­¦è´¨é‡"""
        # è¿™é‡Œå¯ä»¥æ·»åŠ è´¨é‡æ£€æŸ¥å’Œæ”¹è¿›é€»è¾‘
        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¤å…¸æ–‡å­¦å…ƒç´ 
        # éªŒè¯è¯­è¨€é£æ ¼æ˜¯å¦ç¬¦åˆè¦æ±‚
        # è°ƒæ•´å†…å®¹é•¿åº¦å’Œç»“æ„

        return content

    def _process_feedback_messages(self, feedback_messages: List) -> Dict[str, Any]:
        """å¤„ç†åé¦ˆæ¶ˆæ¯"""
        improvement_context = {
            "quality_issues": [],
            "suggestions": [],
            "target_score": 7.0
        }
        
        for message in feedback_messages:
            if message.message_type.value == "feedback":
                content = message.content
                if content.get("type") == "improvement_request":
                    improvement_context["quality_issues"].extend(
                        content.get("quality_issues", {}).items()
                    )
                    improvement_context["suggestions"].extend(
                        content.get("suggestions", [])
                    )
                    improvement_context["target_score"] = content.get("target_score", 7.0)
        
        return improvement_context

    async def _generate_improved_content(self, input_data: Dict[str, Any], improvement_context: Dict[str, Any]) -> AgentResult:
        """åŸºäºåé¦ˆç”Ÿæˆæ”¹è¿›å†…å®¹"""
        print("ğŸ”„ [DEBUG] å¼€å§‹åŸºäºåé¦ˆç”Ÿæˆæ”¹è¿›å†…å®¹")
        
        try:
            # è·å–ä¹‹å‰çš„å†…å®¹
            previous_content = input_data.get("previous_content", {})
            quality_feedback = input_data.get("quality_feedback", {})
            suggestions = input_data.get("improvement_suggestions", [])
            
            print(f"ğŸ”„ [DEBUG] æ”¹è¿›å»ºè®®æ•°é‡: {len(suggestions)}")
            print(f"ğŸ”„ [DEBUG] è´¨é‡åé¦ˆ: {quality_feedback}")
            
            # æ„å»ºæ”¹è¿›æç¤º
            improvement_prompt = self._build_improvement_prompt(
                suggestions, 
                quality_feedback.get("detailed_scores", {}),
                previous_content
            )
            
            # é‡æ–°ç”Ÿæˆå†…å®¹
            if previous_content.get("chapters"):
                improved_chapters = []
                
                for i, chapter in enumerate(previous_content["chapters"]):
                    print(f"ğŸ”„ [DEBUG] æ”¹è¿›ç¬¬ {i+1} ç« ")
                    
                    # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆæ”¹è¿›ç‰ˆæœ¬
                    improved_chapter = await self._improve_chapter_content(
                        chapter, 
                        improvement_prompt,
                        input_data.get("strategy", {}),
                        input_data.get("knowledge_base", {})
                    )
                    
                    improved_chapters.append(improved_chapter)
                
                result_data = {
                    "chapters": improved_chapters,
                    "total_chapters": len(improved_chapters),
                    "improvement_applied": True,
                    "improvement_iteration": input_data.get("iteration", 1),
                    "generation_stats": {
                        "success_rate": 1.0,
                        "average_length": sum(len(c) for c in improved_chapters) / len(improved_chapters) if improved_chapters else 0,
                        "total_words": sum(len(c) for c in improved_chapters)
                    }
                }
                
                print(f"ğŸ”„ [DEBUG] æ”¹è¿›å®Œæˆï¼Œç”Ÿæˆ {len(improved_chapters)} ä¸ªç« èŠ‚")
                
                self.update_status("completed")
                return AgentResult(
                    success=True,
                    data=result_data,
                    message=f"åŸºäºåé¦ˆæˆåŠŸæ”¹è¿›å†…å®¹ï¼Œå…±{len(improved_chapters)}ç« "
                )
            
            else:
                # å¦‚æœæ²¡æœ‰ä¹‹å‰çš„å†…å®¹ï¼ŒæŒ‰æ­£å¸¸æµç¨‹ç”Ÿæˆ
                return await self._generate_normal_content(input_data)
                
        except Exception as e:
            print(f"ğŸ”„ [DEBUG] æ”¹è¿›å†…å®¹ç”Ÿæˆå¤±è´¥: {e}")
            import traceback
            print(f"ğŸ”„ [DEBUG] é”™è¯¯è¯¦æƒ…:\n{traceback.format_exc()}")
            
            self.update_status("error")
            return AgentResult(
                success=False,
                data=None,
                message=f"æ”¹è¿›å†…å®¹ç”Ÿæˆå¤±è´¥: {str(e)}"
            )

    async def _improve_chapter_content(self, original_chapter: str, improvement_prompt: str, 
                                     strategy_data: Dict[str, Any], knowledge_base: Dict[str, Any]) -> str:
        """æ”¹è¿›å•ä¸ªç« èŠ‚å†…å®¹"""
        try:
            # æ„å»ºæ”¹è¿›æç¤º
            prompt = f"""
{improvement_prompt}

åŸå§‹ç« èŠ‚å†…å®¹ï¼š
{original_chapter}

è¯·åŸºäºä»¥ä¸Šæ”¹è¿›å»ºè®®ï¼Œé‡æ–°åˆ›ä½œè¿™ä¸ªç« èŠ‚ï¼Œè¦æ±‚ï¼š
1. ä¿æŒæ•…äº‹æƒ…èŠ‚çš„è¿è´¯æ€§
2. æå‡æ–‡å­¦è´¨é‡å’Œå¤å…¸éŸµå‘³
3. å¢å¼ºäººç‰©æ€§æ ¼çš„è¡¨ç°
4. ä¼˜åŒ–è¯­è¨€è¡¨è¾¾å’Œä¿®è¾æ‰‹æ³•
5. ç¡®ä¿ä¸ã€Šçº¢æ¥¼æ¢¦ã€‹åŸè‘—é£æ ¼ä¸€è‡´

è¯·ç”Ÿæˆæ”¹è¿›åçš„ç« èŠ‚å†…å®¹ï¼š
"""
            
            # è°ƒç”¨GPTç”Ÿæˆæ”¹è¿›å†…å®¹
            response = await self.gpt5_client.generate_content(
                prompt=prompt,
                system_message=self.prompts.get_template("content_generator").system_message,
                temperature=0.7,
                max_tokens=4000
            )
            
            if response.get("success"):
                improved_content = response.get("content", "")
                print(f"ğŸ”„ [DEBUG] ç« èŠ‚æ”¹è¿›æˆåŠŸï¼Œé•¿åº¦: {len(improved_content)}")
                return improved_content
            else:
                print(f"ğŸ”„ [DEBUG] ç« èŠ‚æ”¹è¿›å¤±è´¥ï¼Œä¿æŒåŸå†…å®¹")
                return original_chapter
                
        except Exception as e:
            print(f"ğŸ”„ [DEBUG] ç« èŠ‚æ”¹è¿›å¼‚å¸¸: {e}")
            return original_chapter

    def _build_improvement_prompt(self, suggestions: List[str], quality_issues: Dict[str, Any], 
                                previous_content: Dict[str, Any]) -> str:
        """æ„å»ºæ”¹è¿›æç¤º"""
        prompt_parts = ["åŸºäºè´¨é‡è¯„ä¼°åé¦ˆï¼Œè¯·æ”¹è¿›ä»¥ä¸‹å†…å®¹ï¼š\n"]
        
        if suggestions:
            prompt_parts.append("### å…·ä½“æ”¹è¿›å»ºè®®ï¼š")
            for i, suggestion in enumerate(suggestions, 1):
                prompt_parts.append(f"{i}. {suggestion}")
            prompt_parts.append("")
        
        if quality_issues:
            prompt_parts.append("### éœ€è¦æ”¹è¿›çš„è´¨é‡ç»´åº¦ï¼š")
            for dimension, score in quality_issues.items():
                if isinstance(score, (int, float)) and score < 7.0:
                    prompt_parts.append(f"- {dimension}: å½“å‰{score}/10ï¼Œéœ€è¦æå‡è‡³7.0ä»¥ä¸Š")
            prompt_parts.append("")
        
        prompt_parts.extend([
            "### æ”¹è¿›é‡ç‚¹ï¼š",
            "1. å¢å¼ºå¤å…¸æ–‡å­¦éŸµå‘³å’Œè¯­è¨€é›…è‡´åº¦",
            "2. æ·±åŒ–äººç‰©æ€§æ ¼åˆ»ç”»å’Œå¿ƒç†æå†™", 
            "3. ä¼˜åŒ–æƒ…èŠ‚é€»è¾‘å’Œæ•…äº‹è¿è´¯æ€§",
            "4. æå‡ä¿®è¾æ‰‹æ³•å’Œæ–‡å­¦è¡¨ç°åŠ›",
            "5. ç¡®ä¿ä¸ã€Šçº¢æ¥¼æ¢¦ã€‹åŸè‘—é£æ ¼é«˜åº¦ä¸€è‡´",
            ""
        ])
        
        return "\n".join(prompt_parts)

    async def _generate_normal_content(self, input_data: Dict[str, Any]) -> AgentResult:
        """æ­£å¸¸å†…å®¹ç”Ÿæˆæµç¨‹"""
        # è¿™é‡Œè°ƒç”¨åŸæ¥çš„ç”Ÿæˆé€»è¾‘
        strategy_data = input_data.get("strategy", {})
        chapters_to_generate = input_data.get("chapters", 40)
        plot_outline = strategy_data.get("plot_outline", [])
        
        generated_chapters = []
        
        for i, chapter_info in enumerate(plot_outline[:chapters_to_generate]):
            chapter_content = await self._generate_chapter_content(
                chapter_info,
                strategy_data,
                input_data.get("knowledge_base", {})
            )
            
            if chapter_content["success"]:
                generated_chapters.append(chapter_content["content"])
            else:
                fallback_content = self._generate_fallback_content(chapter_info)
                generated_chapters.append(fallback_content)
        
        result_data = {
            "chapters": generated_chapters,
            "total_chapters": len(generated_chapters),
            "generation_stats": {
                "success_rate": len([c for c in generated_chapters if "error" not in c]) / len(generated_chapters) if generated_chapters else 0,
                "average_length": sum(len(c) for c in generated_chapters) / len(generated_chapters) if generated_chapters else 0,
                "total_words": sum(len(c) for c in generated_chapters)
            }
        }
        
        self.update_status("completed")
        return AgentResult(
            success=True,
            data=result_data,
            message=f"æˆåŠŸç”Ÿæˆ{len(generated_chapters)}ç« ç»­å†™å†…å®¹"
        )

    def _add_literary_elements(self, content: str, chapter_info: Dict[str, Any]) -> str:
        """æ·»åŠ æ–‡å­¦å…ƒç´ """
        # æ ¹æ®ç« èŠ‚ç‰¹ç‚¹æ·»åŠ åˆé€‚çš„æ–‡å­¦å…ƒç´ 
        # å¦‚è¯—è¯ã€å¯¹è”ã€è±¡å¾æ‰‹æ³•ç­‰

        return content
